{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a80fdf7",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb459b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4389a41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "\n",
       "[1 rows x 784 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = train.drop([\"label\"], axis=1) ,train.label\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a7d607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3abaa",
   "metadata": {},
   "source": [
    "- Each row has 1 label value indicating the number and 784(28*28) pixel columns for indicating rgb numbers(0-255) of each pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a1cc996f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11       9\n",
       "27       9\n",
       "28       9\n",
       "31       9\n",
       "33       9\n",
       "        ..\n",
       "41962    9\n",
       "41969    9\n",
       "41975    9\n",
       "41992    9\n",
       "41999    9\n",
       "Name: label, Length: 4188, dtype: int64"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7bcaea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcba73d7",
   "metadata": {},
   "source": [
    "## RGB to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610d578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def print_img(pixel_df, index):\n",
    "    digit_image = pixel_df.iloc[index].values.reshape((28,28))\n",
    "    plt.imshow(digit_image, cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9e0743b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_img(X, 41962)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08cfe9",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "970556ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a1528b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('sgdclassifier', SGDClassifier(random_state=0))])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                    SGDClassifier(random_state = 0))\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "02025c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9102380952380953"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "clf_acc = accuracy_score(y_val, y_pred)\n",
    "clf_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "57f23e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open(\"models/sgd_classifier\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "445fd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.reset_index(drop=True, inplace = True)\n",
    "def clf_predict(pixel_df, index):\n",
    "    pixel_df.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "    print(\"Image making prediction on\"), print_img(pixel_df, index), print(\"Prediction is: \" + str(clf.predict(pixel_df.loc[[index]])));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1ebd9065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image making prediction on\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAGcklEQVR4nO3dz4vN/R/G8XPkdyk1oSSRtYayUBb2IgkrMX8CWVEsSNmwkfxKWLHApBSlJllZyGYWk4woSshGokE6339gPq/zvc8x5prxeCxdvc+czfP+1P3unNPudDotIM+c6X4DwOTECaHECaHECaHECaHmVmO73fa/cmGKdTqd9mT/7skJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJoeZO9xvg71qxYkW5r127tufXHh8fL/dFixaV+5YtWxq3o0ePlmcHBwfL/eDBg+V+7ty5cp8OnpwQSpwQSpwQSpwQSpwQSpwQSpwQqt3pdJrHdrt5ZErMnz+/3Hft2lXu3e4DBwYGyn3lypXlXnn37l25L1iwoNyXL1/e89/+/ft3ua9Zs6bc379/3/Pf7len02lP9u+enBBKnBBKnBBKnBBKnBBKnBBKnBDK5zmnQXWf9+jRo/Ls+vXr+/rb3e7zHj9+3LitXr26PLtu3bqe3tP/Y2JiotwPHDhQ7tN5j9krT04IJU4IJU4IJU4IJU4IJU4IJU4I5Z5zCnS7DxweHm7cut1jfvnypdyHhobK/enTp+X++fPnxm3p0qXl2ep7Z1utVuvWrVvlPm/evMbt9OnT5dm7d++W+0zkyQmhxAmhxAmhxAmhxAmhxAmhxAmhfG9tD7r9xuXY2Fi5V/eF3759K89u3ry5r7/dj+oestVqtUZGRsq92z3ovXv3Grfdu3eXZ2cy31sLM4w4IZQ4IZQ4IZQ4IZQ4IZSPjE2i21XJgwcPyr3bR6u+f//euB07dqw8O5VXJa1Wq7Vw4cLG7fLly+XZblclr169KvcTJ06U+7/GkxNCiRNCiRNCiRNCiRNCiRNCiRNCueecxMmTJ8t9w4YNfb3++fPnG7dz58719dr9WrVqVeO2Y8eOvl777Nmz5T46OtrX6882npwQSpwQSpwQSpwQSpwQSpwQSpwQatbec86Z0/zfna1bt5Zn9+7dW+7dvr7yxYsX5X7p0qVyn0oDAwPlXt3xLlmypDx74cKFcp+NP9M3lTw5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdSs/QnA6jOXz58/7+u1h4eHy31oaKjcq++t7Ve3e8xun6ncv39/49bt85bdfqbv9evX5f6v8hOAMMOIE0KJE0KJE0KJE0KJE0KJE0LN2s9zvnz5snEbHx8vzz579qzcjx8/Xu5TeY/Zzb59+8q9usdstVqtjx8/Nm6HDx8uz7rH/LM8OSGUOCGUOCGUOCGUOCGUOCHUrP3IWKXbVzz+/Pmz3H/8+PEn385/Mnduffv19u3bcl+2bFm5nzhxonE7c+ZMeXZiYqLcmZyPjMEMI04IJU4IJU4IJU4IJU4IJU4INWs/Mlb5+vXrdL+FRosXLy7369evl/uKFSvK/ebNm+V+6tSpcufv8eSEUOKEUOKEUOKEUOKEUOKEUOKEUP/kPWey7du3l/uePXvK/dOnT+V+48aN//qWmCaenBBKnBBKnBBKnBBKnBBKnBBKnBDKPWeYXbt29XX+zp075T4yMtLX6/P3eHJCKHFCKHFCKHFCKHFCKHFCKFcp02DTpk2N286dO8uzo6Oj5X7x4sWe3hN5PDkhlDghlDghlDghlDghlDghlDghlHvOKdDtZ/yuXLnSuP369as8e+3atXIfGxsrd2YOT04IJU4IJU4IJU4IJU4IJU4IJU4I5Z5zCmzbtq3cBwcHG7f79++XZ2/fvt3Te2Lm8eSEUOKEUOKEUOKEUOKEUOKEUOKEUO45p8CRI0d6PvvkyZNy//DhQ8+vzcziyQmhxAmhxAmhxAmhxAmhxAmhxAmh3HP24NChQ+W+cePGcn/z5k3jdvXq1V7eErOQJyeEEieEEieEEieEEieEEieEcpXSg/Hx8b7OP3z4sHH7/v17X6/N7OHJCaHECaHECaHECaHECaHECaHECaHanU6neWy3m0fgj+h0Ou3J/t2TE0KJE0KJE0KJE0KJE0KJE0KJE0KV95zA9PHkhFDihFDihFDihFDihFDihFD/A4a6ERBuNVHNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is: [7]\n"
     ]
    }
   ],
   "source": [
    "clf_predict(X_val, 2221)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ceab5",
   "metadata": {},
   "source": [
    "## Basic ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b61f1506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "X_train = X_train / 255\n",
    "X_val = X_val / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20beb9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 0.5711 - accuracy: 0.8557\n",
      "Epoch 2/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.9065\n",
      "Epoch 3/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2958 - accuracy: 0.9158\n",
      "Epoch 4/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2796 - accuracy: 0.9214\n",
      "Epoch 5/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2682 - accuracy: 0.9241\n",
      "Epoch 6/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2619 - accuracy: 0.9258\n",
      "Epoch 7/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2561 - accuracy: 0.9274\n",
      "Epoch 8/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2516 - accuracy: 0.9286\n",
      "Epoch 9/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2473 - accuracy: 0.9303\n",
      "Epoch 10/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.2440 - accuracy: 0.9299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2db48821a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab96e94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 1s 2ms/step - loss: 0.2759 - accuracy: 0.9258\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_val, y_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9887524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_predict(pixel_df, index):\n",
    "    pixel_df.reset_index(drop=True, inplace = True)\n",
    "    print(\"Image making prediction on\"), print_img(pixel_df, index) \n",
    "    prediction = np.argmax(model.predict(pixel_df.iloc[[index]]))\n",
    "    print(f\"Prediction is {prediction} with {model.predict(pixel_df.iloc[[index]])[0][prediction]} probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0ce7b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image making prediction on\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is 6 with 0.9820855259895325 probability\n"
     ]
    }
   ],
   "source": [
    "ann_predict(X_val, 240)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f148d9fa",
   "metadata": {},
   "source": [
    "## ANN with Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b2c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3400 - accuracy: 0.9029\n",
      "Epoch 2/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1545 - accuracy: 0.9557\n",
      "Epoch 3/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.1101 - accuracy: 0.9672\n",
      "Epoch 4/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.9754\n",
      "Epoch 5/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0639 - accuracy: 0.9810\n",
      "Epoch 6/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0541 - accuracy: 0.9836\n",
      "Epoch 7/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0417 - accuracy: 0.9874\n",
      "Epoch 8/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0327 - accuracy: 0.9905\n",
      "Epoch 9/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0263 - accuracy: 0.9929\n",
      "Epoch 10/10\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.0228 - accuracy: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2db4cedec10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adb370e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 1s 2ms/step - loss: 0.1135 - accuracy: 0.9696\n"
     ]
    }
   ],
   "source": [
    "model2.evaluate(X_val, y_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e0d7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_predict2(pixel_df, index):\n",
    "    pixel_df.reset_index(drop=True, inplace = True)\n",
    "    print(\"Image making prediction on\"), print_img(pixel_df, index) \n",
    "    prediction = np.argmax(model2.predict(pixel_df.iloc[[index]]))\n",
    "    print(f\"Prediction is {prediction} with {model2.predict(pixel_df.iloc[[index]])[0][prediction]} probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c9f95f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.17495579e-03, 9.13569456e-05, 1.01414006e-02, 9.99944210e-01,\n",
       "        2.54257460e-09, 9.81258392e-01, 9.09214898e-04, 1.07607426e-04,\n",
       "        8.88664126e-01, 1.30293459e-01]], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(X_val.iloc[[0]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f2147892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[1 rows x 784 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd3b6f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image making prediction on\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAGUElEQVR4nO3dT4hNfQDG8XulTGpYWGk2SqFsbFAaEZkVVhRJFpINNRayVWqUlWFBsZEsWNmQjSzMZqwky1n401igWGqGzrt7N++c3+Uex33u6/NZztM9Z1Lf99T768ztVlXVAfIsG/QvACxNnBBKnBBKnBBKnBBqeWnsdrv+Vy60rKqq7lI/9+SEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUMsH/QvAz1i5cmVxf/r0aXHfunVrcd+9e3dxn5mZKe5t8OSEUOKEUOKEUOKEUOKEUOKEUI5SBmDTpk2124ULF4qfffnyZXGfnp7u51eKMDo6Wrs9fvy4+Nnt27c3uveuXbuKu6MU4F/ihFDihFDihFDihFDihFDihFDdqqrqx263fqRWr7PGU6dO1W4jIyPFz/748aO4j4+PF/fZ2dniPkhjY2O12/v37xtde2FhobivWrWq0eebqKqqu9TPPTkhlDghlDghlDghlDghlDghlDghlPc5+1B6H7PT6XSOHTtW3HudZZY8fPiwuH/69Knva7et11ninTt3Wrv3ixcvinub55j98uSEUOKEUOKEUOKEUOKEUOKEUOKEUM45l3DixInifvXq1eK+evXqvu/97t274n7+/Pni/ubNm77v3baJiYnivmfPnr6vvbi4WNynpqb6vvageHJCKHFCKHFCKHFCKHFCKHFCKHFCqL/ynPPIkSPF/dKlS8W9yTlmp9PpPHr0qHY7efJk8bMfP35sdO829fp3OXfuXGv3vnz5cnF/8uRJa/duiycnhBInhBInhBInhBInhBInhPrffgVg6bWuM2fOFD+7bFmz/2b1eu1r//79tdvr168b3XuQDh06VNwfPHjQ97W/fv1a3NevX1/cv3z50ve92+YrAGHIiBNCiRNCiRNCiRNCiRNCiRNCDe0rY6dPny7uZ8+erd263SWPlX5ak3PMTmd4zzI3bNhQ3G/fvt3o+t++favder1ulnyO2S9PTgglTgglTgglTgglTgglTgglTgg1tO9zzs/PF/e1a9e2du/Pnz8X97dv3xb36enpvq/dtrGxsdptcnKy+NnNmzc3unfpa/xevXpV/GzpjLTT6XSOHz9e3Af51Yne54QhI04IJU4IJU4IJU4IJU4IJU4INbTnnKXf+2d2/i5zc3PFvde7qm1yzglDRpwQSpwQSpwQSpwQSpwQSpwQamjPOZ8/f17cd+zYUbs1/bu1DJ+FhYXiPjIy8od+k/9yzglDRpwQSpwQSpwQSpwQSpwQami/AnDnzp3FfWJionbrdZSybdu24n7gwIHiPkijo6PFfePGja3de3Z2trhfvHix72sfPHiwuPf6k6IzMzN933tQPDkhlDghlDghlDghlDghlDghlDgh1NC+MsbSjh49Wtzv3bvX97V7fU3e+Ph4cf/w4UPf9/4/88oYDBlxQihxQihxQihxQihxQihxQqihfZ/zb7Vv377ifu3atdbufevWreLuHPP38uSEUOKEUOKEUOKEUOKEUOKEUOKEUM45h8zU1FRxX7NmTaPrX7lypXa7e/duo2vzazw5IZQ4IZQ4IZQ4IZQ4IZQ4IZSjlDBbtmwp7uvWrWt0/bm5ueJ+/fr12m1+fr7Rvfk1npwQSpwQSpwQSpwQSpwQSpwQSpwQyjnnAKxYsaJ2m5ycLH621ythi4uLxf3GjRvF3VlmDk9OCCVOCCVOCCVOCCVOCCVOCCVOCNWtqqp+7HbrR/p2+PDh2u3+/fuNrv3s2bPivnfv3kbX5/erqqq71M89OSGUOCGUOCGUOCGUOCGUOCGUOCGU9zkHoNtd8ljrt/j+/Xtr1+bP8uSEUOKEUOKEUOKEUOKEUOKEUOKEUM45h8zNmzeL+9TU1B/6TWibJyeEEieEEieEEieEEieEEieE8qcxYcD8aUwYMuKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUMX3OYHB8eSEUOKEUOKEUOKEUOKEUOKEUP8AS14hQrGB2q8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is 4 with 1.0 probability\n"
     ]
    }
   ],
   "source": [
    "ann_predict2(X_val, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "da7daf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/digit_predicter_ann\\assets\n"
     ]
    }
   ],
   "source": [
    "model2.save('models/digit_predicter_ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef9fcb",
   "metadata": {},
   "source": [
    "### Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d26ef376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 28, 28, 1)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped = [i.reshape((28,28)) for i in X_train.values]\n",
    "X_train_reshaped = np.array(X_train_reshaped)\n",
    "X_train_reshaped = X_train_reshaped.reshape(-1, 28, 28, 1)\n",
    "X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4804092d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1050/1050 [==============================] - 4s 3ms/step - loss: 0.5468 - accuracy: 0.8377\n",
      "Epoch 2/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0803 - accuracy: 0.9747\n",
      "Epoch 3/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0526 - accuracy: 0.9830\n",
      "Epoch 4/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0398 - accuracy: 0.9877\n",
      "Epoch 5/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0295 - accuracy: 0.9909\n",
      "Epoch 6/20\n",
      "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0214 - accuracy: 0.9931\n",
      "Epoch 7/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0190 - accuracy: 0.9938\n",
      "Epoch 8/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0145 - accuracy: 0.9955\n",
      "Epoch 9/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0102 - accuracy: 0.9970\n",
      "Epoch 10/20\n",
      "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0121 - accuracy: 0.9960\n",
      "Epoch 11/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0099 - accuracy: 0.9968\n",
      "Epoch 12/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0077 - accuracy: 0.9976\n",
      "Epoch 13/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0080 - accuracy: 0.9975\n",
      "Epoch 14/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 15/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 16/20\n",
      "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 17/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 18/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0046 - accuracy: 0.9983\n",
      "Epoch 19/20\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 20/20\n",
      "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0022 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2db4e7aba60>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "cnn = models.Sequential([\n",
    "    # cnn\n",
    "    layers.Conv2D(filters=12, kernel_size=(3, 3),input_shape=(28,28,1), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(filters=24, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    # dense\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer='adam', \n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(X_train_reshaped, y_train, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "84febacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 1s 2ms/step - loss: 0.0649 - accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "X_val_reshaped = [i.reshape((28,28)) for i in X_val.values]\n",
    "X_val_reshaped = np.array(X_val_reshaped)\n",
    "X_val_reshaped = X_val_reshaped.reshape(-1, 28, 28, 1)\n",
    "cnn.evaluate(X_val_reshaped, y_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d53a9998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/digit_predicter_cnn\\assets\n"
     ]
    }
   ],
   "source": [
    "cnn.save('models/digit_predicter_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8841b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reshaped = [i.reshape((28,28)) for i in test.values]\n",
    "test_reshaped = np.array(test_reshaped)\n",
    "test_reshaped = test_reshaped.reshape(-1, 28, 28, 1) / 255\n",
    "predictions = cnn.predict(test_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "9ee68a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [i.argmax() for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f7d1c202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      0\n",
       "1            2      0\n",
       "2            3      0\n",
       "3            4      0\n",
       "4            5      0\n",
       "...        ...    ...\n",
       "27995    27996      0\n",
       "27996    27997      0\n",
       "27997    27998      0\n",
       "27998    27999      0\n",
       "27999    28000      0\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "25ae22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.Label = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1cf597b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "77c37c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 11, 11, 24)        2616      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 24)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               60100     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 63,846\n",
      "Trainable params: 63,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fdbaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
